import os
from datetime import datetime
from typing import Annotated, Literal, TypedDict
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from pydantic import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from dotenv import load_dotenv

load_dotenv()

# 2. DEFINE TOOLS
# This is the action the agent can take. When it feels the journal entry is 
# complete, it will call this tool to save the file.

class JournalEntry(BaseModel):
    """Schema for the journal entry."""
    content: str = Field(description="The summarized or full text of the journal entry.")
    mood: str = Field(description="A one-word tag describing the user's mood (e.g., Happy, Anxious, Calm).")

@tool(args_schema=JournalEntry)
def save_journal_entry(content: str, mood: str = "Neutral"):
    """
    Saves the finalized journal entry to a markdown file.
    Call this when the user indicates they are done journaling or asks to save.
    """
    date_str = datetime.now().strftime("%Y-%m-%d")
    filename = f"journal_{date_str}.md"
    
    entry_text = f"""# Journal Entry: {date_str}
**Mood:** {mood}

## Content
{content}
---
*Generated by LangGraph Agent*
"""
    
    with open(filename, "a") as f:
        f.write(entry_text)
        
    return f"Successfully saved journal entry to {filename}."

@tool
def read_journal_entries():
    """
    Reads all journal entries from the current directory.
    Use this when the user asks for a summary of their past journals.
    """
    journal_files = [f for f in os.listdir(".") if f.startswith("journal_") and f.endswith(".md")]
    journal_files.sort() # Sort by date (filename)
    
    if not journal_files:
        return "No journal entries found."
    
    all_entries = ""
    for filename in journal_files:
        try:
            with open(filename, "r") as f:
                content = f.read()
                all_entries += f"\n\n=== Entry from {filename} ===\n{content}"
        except Exception as e:
            all_entries += f"\n\nError reading {filename}: {str(e)}"
            
    return all_entries

# 3. DEFINE STATE
# We use 'add_messages' so the graph appends new messages to history 
# rather than overwriting them.
class AgentState(TypedDict):
    messages: Annotated[list, add_messages]

# 4. DEFINE NODES AND LOGIC

# Initialize the LLM
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

# Bind the tool to the LLM
tools = [save_journal_entry, read_journal_entries]
llm_with_tools = llm.bind_tools(tools)

# System prompt to guide the agent's personality
SYSTEM_PROMPT = """You are a compassionate and thoughtful journaling assistant. 
Your goal is to help the user reflect on their day, process emotions, and record their thoughts.

1. Ask one question at a time.
2. Be empathetic but brief.
3. If the user gives a short answer, ask a gentle follow-up to dig deeper.
4. When the user says "I'm done", "Goodbye", or indicates they want to stop, 
   summarize the conversation into a cohesive narrative and call the 'save_journal_entry' tool.
5. If the user asks to summarize their journal or past entries, use the 'read_journal_entries' tool to retrieve the content and then provide a summary.
"""

def chatbot(state: AgentState):
    """The main node that processes user input and generates a response."""
    return {"messages": [llm_with_tools.invoke(
        [SystemMessage(content=SYSTEM_PROMPT)] + state["messages"]
    )]}

# 5. BUILD THE GRAPH

builder = StateGraph(AgentState)

# Add Nodes
builder.add_node("chatbot", chatbot)
builder.add_node("tools", ToolNode(tools))

# Add Edges
builder.add_edge(START, "chatbot")

# Conditional Edge:
# If the LLM decides to call a tool (save_entry), go to 'tools'.
# If the LLM just responds with text, stop (wait for user input).
builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)

# From tools, go back to chatbot to confirm to the user that it was saved.
builder.add_edge("tools", "chatbot")

# Compile the graph with memory (so it remembers the chat context)
memory = MemorySaver()
graph = builder.compile(checkpointer=memory)

# 6. RUN THE INTERACTIVE LOOP
def parse_content(content):
    """
    Helper to parse the content from the LLM, which might be a string
    or a list of dictionaries (e.g. from Google Gemini).
    """
    if isinstance(content, str):
        return content
    elif isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict) and item.get("type") == "text":
                text_parts.append(item.get("text", ""))
        return "".join(text_parts)
    return str(content)

def main():
    print("ðŸ“– Journaling Agent Initialized. Type 'q' or 'quit' to exit manually.")
    print("---------------------------------------------------------------------")
    
    # A unique thread ID allows the graph to maintain state for this specific conversation
    config = {"configurable": {"thread_id": "journal_session_1"}}
    
    # Start the conversation
    while True:
        user_input = input("\nYou: ")
        if user_input.lower() in ["q", "quit"]:
            break

        # Stream the updates from the graph
        events = graph.stream(
            {"messages": [HumanMessage(content=user_input)]},
            config,
            stream_mode="values"
        )
        
        for event in events:
            # Get the last message from the event state
            last_message = event["messages"][-1]
            
            # Only print the message if it's from the AI (assistant)
            if last_message.type == "ai":
                # If there are tool calls, the agent is performing an action (saving)
                if last_message.tool_calls:
                    print(f"\n[Agent is saving your journal entry...]")
                else:
                    print(f"\nAgent: {parse_content(last_message.content)}")

if __name__ == "__main__":
    main()